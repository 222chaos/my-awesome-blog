## 修复后端请求格式匹配前端

### 问题分析
前端发送的请求格式与后端 Schema 不匹配：
- 前端：`message: string`, `conversation_id`, `stream: boolean`
- 后端：`messages: List[LLMMessage]`, 无 `stream` 字段

### 修复计划

#### 1. 修改后端 Schema (`schemas/llm.py`)
- 添加 `message: Optional[str]` 字段（向后兼容）
- 添加 `conversation_id: Optional[str]` 字段
- 添加 `stream: Optional[bool]` 字段
- 保持 `messages` 字段用于现有逻辑

#### 2. 修改后端服务 (`services/llm_service.py`)
- 处理 `message` 单条消息，转换为 `messages` 列表
- 传递 `stream` 参数给底层 LLM

#### 3. 修改后端服务处理 conversation_id
- 如果提供 `conversation_id`，获取历史消息并添加到消息列表