## 移除 LLM 流式端点的用户认证要求

### 问题分析
后端的 `/api/v1/llm/chat/stream` 端点需要用户认证：
- 使用了 `current_user: User = Depends(get_current_active_user)` 依赖
- 如果用户没有登录，返回 401 认证错误

### 修复方案
移除流式端点的用户认证依赖，允许任何人使用 LLM 对话功能：

**修改 `app/api/v1/endpoints/llm.py`：**
- 移除 `current_user: User = Depends(get_current_active_user)` 依赖
- 移除用户日志记录
- 保持其他逻辑不变

这样未登录用户也可以使用 LLM 对话和流式输出功能。